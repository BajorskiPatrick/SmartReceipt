# ğŸ§¾ SmartReceipt AI Module

**SmartReceipt AI Module** to mikroserwis oparty na AI do analizy i kategoryzacji paragonÃ³w.
PeÅ‚ni rolÄ™ backendowego silnika przetwarzania obrazu dla aplikacji **SmartReceipt**.

---

## ğŸ§  Technologia

Silnik opiera siÄ™ na trzech gÅ‚Ã³wnych filarach:

1. **OCR â€” `PaddleOCR`**
   Modele detekcji tekstu sÄ… **wbudowane w obraz** (*Zero-Download Startup*), co zapewnia:

   * bÅ‚yskawiczny start kontenera
   * brak pobierania modeli przy uruchomieniu

2. **LLM â€” `Llama 3.1 8B Instruct (Q4_K_M)`**
   Model jÄ™zykowy odpowiedzialny za strukturyzacjÄ™ danych:

   * wyciÄ…ganie produktÃ³w
   * ceny i iloÅ›ci
   * eksport do formatu JSON

   **Feature:**

   * **Hybrid Mode (GPU Offloading)** â€” umoÅ¼liwia uruchomienie modelu 8B nawet na kartach z **4 GB VRAM**

3. **NLP â€” `SetFit`**
   Model do semantycznej klasyfikacji produktÃ³w, np.:
   *â€Mlekoâ€ â†’ â€SpoÅ¼ywczeâ€*

---

## ğŸš€ Uruchamianie (Docker)

Projekt jest w peÅ‚ni skonteneryzowany. Wymagany jest jedynie **Docker**.

### 1ï¸âƒ£ Pobieranie / Budowanie obrazu

> âš ï¸ Obraz zawiera model Llama oraz PaddleOCR (~6 GB), wiÄ™c pierwsze pobieranie lub budowanie moÅ¼e chwilÄ™ potrwaÄ‡.

#### ğŸ”¹ Opcja A: Pobranie gotowego obrazu (szybka)

```bash
docker pull ghcr.io/janbanasik/ai_module:latest
```

> âš ï¸ JeÅ›li posiadasz starszy procesor i pojawi siÄ™ bÅ‚Ä…d **Exit 132**, skorzystaj z opcji B.

#### ğŸ”¹ Opcja B: Budowanie lokalne (zalecane dla kompatybilnoÅ›ci)

Buduje binarki idealnie dopasowane do Twojego procesora (rozwiÄ…zuje problemy z AVX / AVX2).

```bash
docker build -t ai_module .
```

---

### 2ï¸âƒ£ Uruchamianie kontenera (wybierz tryb)

Wybierz konfiguracjÄ™ odpowiedniÄ… dla Twojego sprzÄ™tu.

---

#### âœ… Opcja A: NVIDIA GPU (4 GB VRAM) â€” **ZALECANE**

Tryb hybrydowy: czÄ™Å›Ä‡ modelu Å‚adowana do GPU, reszta do RAM.

```bash
# SR_GPU_LAYERS=15 to bezpieczna wartoÅ›Ä‡ dla kart 4GB VRAM
docker run --rm --gpus all \
  -e SR_GPU_LAYERS=15 \
  -p 8000:8000 \
  --name receipt_ai \
  ghcr.io/janbanasik/ai_module:latest
```

---

#### ğŸï¸ Opcja B: NVIDIA GPU (8 GB+ VRAM)

CaÅ‚y model Å‚adowany do GPU â€” maksymalna wydajnoÅ›Ä‡
â±ï¸ ~2â€“3 sekundy na paragon

```bash
docker run --rm --gpus all \
  -e SR_GPU_LAYERS=33 \
  -p 8000:8000 \
  --name receipt_ai \
  ghcr.io/janbanasik/ai_module:latest
```

---

#### ğŸ¢ Opcja C: Tryb CPU (brak GPU)

DziaÅ‚a na kaÅ¼dym komputerze, ale znacznie wolniej:
â±ï¸ ~60â€“90 sekund na paragon

```bash
docker run --rm \
  -e SR_GPU_LAYERS=0 \
  -p 8000:8000 \
  --name receipt_ai \
  ghcr.io/janbanasik/ai_module:latest
```

---

## âš™ï¸ Konfiguracja (zmienne Å›rodowiskowe)

Kontener moÅ¼na konfigurowaÄ‡ za pomocÄ… flag `-e`:

| Zmienna                 | DomyÅ›lnie | Opis                                      |
| ----------------------- | --------- | ----------------------------------------- |
| `SR_GPU_LAYERS`         | `15`      | Liczba warstw modelu Å‚adowanych do VRAM   |
|                         |           | `0` â†’ CPU only                            |
|                         |           | `15` â†’ Hybrid (4 GB GPU)                  |
|                         |           | `33` â†’ Full GPU (8 GB+ GPU)               |

---

## ğŸ“¡ Dokumentacja API

Po uruchomieniu serwera dostÄ™pna jest peÅ‚na, interaktywna dokumentacja **Swagger UI**:

ğŸ‘‰ **[http://localhost:8000/docs](http://localhost:8000/docs)**

---

### ğŸ”¹ GÅ‚Ã³wny endpoint

**POST** `/api/v1/ocr/process`

**Input:**
`multipart/form-data`

* klucz: `file`

**Output:**
JSON zawierajÄ…cy listÄ™ produktÃ³w oraz przypisane kategorie.

#### ğŸ“„ PrzykÅ‚adowa odpowiedÅº

```json
{
  "items": [
    {
      "productName": "Mleko 3.2%",
      "price": 3.99,
      "quantity": 2.0,
      "category": "SpoÅ¼ywcze"
    }
  ]
}
```
