# ğŸ§¾ SmartReceipt AI Module

**SmartReceipt AI Module** to mikroserwis oparty na AI do analizy i kategoryzacji paragonÃ³w.  
PeÅ‚ni rolÄ™ backendowego silnika przetwarzania obrazu dla aplikacji **SmartReceipt**.

---

## ğŸ§  Technologia

Silnik opiera siÄ™ na trzech gÅ‚Ã³wnych filarach:

### 1. OCR â€” `PaddleOCR`
Modele detekcji tekstu sÄ… **wbudowane w obraz** (*Zero-Download Startup*), co zapewnia:
- bÅ‚yskawiczny start kontenera (offline ready)
- brak pobierania modeli przy uruchomieniu

### 2. LLM â€” `Llama 3.1 8B Instruct (Q4_K_M)`
Model jÄ™zykowy odpowiedzialny za strukturyzacjÄ™ danych:
- wyciÄ…ganie produktÃ³w, cen i iloÅ›ci
- eksport do formatu JSON

**Feature:**
- **Hybrid Mode (GPU Offloading)** â€” umoÅ¼liwia uruchomienie modelu 8B nawet na kartach z **4 GB VRAM**

### 3. NLP â€” `SetFit`
Model do semantycznej klasyfikacji produktÃ³w, np.  
*â€Mlekoâ€ â†’ â€SpoÅ¼ywczeâ€*

---

## ğŸš€ Uruchamianie (Docker)

Projekt jest w peÅ‚ni skonteneryzowany. Wymagany jest jedynie **Docker**.

### 1ï¸âƒ£ Pobieranie / Budowanie obrazu

> âš ï¸ Obraz zawiera â€wypieczoneâ€ modele Llama, SetFit oraz PaddleOCR (~6 GB),  
> dlatego budowa lub pobieranie moÅ¼e potrwaÄ‡ kilkanaÅ›cie minut.

#### ğŸ”¹ Opcja A: Pobranie gotowego obrazu (szybka)

```bash
docker pull ghcr.io/janbanasik/ai_module:latest
```

> âš ï¸ JeÅ›li posiadasz starszy procesor / procesor uÅ¼ywajÄ…cy innej architektury i po uruchomieniu pojawi siÄ™ bÅ‚Ä…d **Exit 132**,  
> skorzystaj z opcji B.

#### ğŸ”¹ Opcja B: Budowanie lokalne (zalecane)

Buduje binarki dopasowane do Twojego procesora  
(rozwiÄ…zuje problemy z instrukcjami AVX / AVX2).

```bash
docker build -t ai_module .
```

---

### 2ï¸âƒ£ Uruchamianie kontenera (wybierz tryb)

> JeÅ›li budowaÅ‚eÅ› lokalnie, zamieÅ„  
> `ghcr.io/janbanasik/ai_module:latest` â†’ `ai_module`

#### âœ… Opcja A: NVIDIA GPU (4 GB VRAM) â€” **ZALECANE**
Tryb hybrydowy: czÄ™Å›Ä‡ modelu w GPU, reszta w RAM.

```bash
docker run --rm --gpus all \
  -e SR_GPU_LAYERS=15 \
  -p 8000:8000 \
  --name receipt_ai \
  ghcr.io/janbanasik/ai_module:latest
```

#### ğŸï¸ Opcja B: NVIDIA GPU (8 GB+ VRAM)
CaÅ‚y model Å‚adowany do GPU â€” maksymalna wydajnoÅ›Ä‡.  
â±ï¸ ~2â€“3 sekundy na paragon

```bash
docker run --rm --gpus all \
  -e SR_GPU_LAYERS=33 \
  -p 8000:8000 \
  --name receipt_ai \
  ghcr.io/janbanasik/ai_module:latest
```

#### ğŸ¢ Opcja C: Tryb CPU (brak GPU)
DziaÅ‚a na kaÅ¼dym komputerze, ale znacznie wolniej.  
â±ï¸ ~60â€“90 sekund na paragon

> â„¹ï¸ W logach moÅ¼e pojawiÄ‡ siÄ™ komunikat:  
> `WARNING: The NVIDIA Driver was not detected.`  
> Jest to normalne â€” system automatycznie przeÅ‚Ä…czy siÄ™ na CPU.

```bash
docker run --rm \
  -e SR_GPU_LAYERS=0 \
  -p 8000:8000 \
  --name receipt_ai \
  ghcr.io/janbanasik/ai_module:latest
```

---

## âš™ï¸ Konfiguracja (zmienne Å›rodowiskowe)

| Zmienna         | DomyÅ›lnie | Opis |
|-----------------|-----------|------|
| `SR_GPU_LAYERS` | `15` | Liczba warstw modelu Å‚adowanych do VRAM<br>`0` â†’ CPU only<br>`15` â†’ Hybrid (4 GB GPU)<br>`33` â†’ Full GPU (8 GB+) |

---

## ğŸ“¡ Dokumentacja API

Po uruchomieniu serwera dostÄ™pna jest interaktywna dokumentacja Swagger UI:

ğŸ‘‰ **http://localhost:8000/docs**

### ğŸ”¹ GÅ‚Ã³wny endpoint

**POST** `/api/v1/ocr/process`

**Input:** `multipart/form-data`  
- `file` â€” obraz paragonu

**Output:** JSON zawierajÄ…cy listÄ™ produktÃ³w i przypisane kategorie.

#### ğŸ“„ PrzykÅ‚adowa odpowiedÅº

```json
{
  "items": [
    {
      "productName": "Mleko 3.2%",
      "price": 3.99,
      "quantity": 2.0,
      "category": "SpoÅ¼ywcze"
    }
  ]
}
```
